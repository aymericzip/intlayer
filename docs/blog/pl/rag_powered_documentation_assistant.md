---
createdAt: 2025-09-10
updatedAt: 2025-09-10
title: Budowanie asystenta dokumentacji opartego na RAG (dzielenie na fragmenty, osadzenia i wyszukiwanie)
description: Budowanie asystenta dokumentacji opartego na RAG (dzielenie na fragmenty, osadzenia i wyszukiwanie)
keywords:
  - RAG
  - Dokumentacja
  - Asystent
  - Dzielenie na fragmenty
  - Osadzenia
  - Wyszukiwanie
slugs:
  - blog
  - rag-powered-documentation-assistant
---

# Budowanie asystenta dokumentacji opartego na RAG (dzielenie na fragmenty, osadzenia i wyszukiwanie)

## Co otrzymujesz

ZbudowaÅ‚em asystenta dokumentacji opartego na RAG i zapakowaÅ‚em go w boilerplate, ktÃ³rego moÅ¼esz od razu uÅ¼yÄ‡.

- Zawiera gotowÄ… do uÅ¼ycia aplikacjÄ™ (Next.js + OpenAI API)
- Zawiera dziaÅ‚ajÄ…cy pipeline RAG (dzielenie na fragmenty, osadzenia, podobieÅ„stwo cosinusowe)
- Zapewnia kompletny interfejs chatbota zbudowany w React
- Wszystkie komponenty UI sÄ… w peÅ‚ni edytowalne za pomocÄ… Tailwind CSS
- Rejestruje kaÅ¼de zapytanie uÅ¼ytkownika, aby pomÃ³c zidentyfikowaÄ‡ brakujÄ…ce dokumenty, problemy uÅ¼ytkownikÃ³w i moÅ¼liwoÅ›ci produktowe

ğŸ‘‰Â [Demo na Å¼ywo](https://intlayer.org/doc/why) ğŸ‘‰Â [Boilerplate kodu](https://github.com/aymericzip/smart_doc_RAG)

## Wprowadzenie

JeÅ›li kiedykolwiek zgubiÅ‚eÅ› siÄ™ w dokumentacji, przewijajÄ…c bez koÅ„ca w poszukiwaniu jednej odpowiedzi, wiesz, jak to moÅ¼e byÄ‡ frustrujÄ…ce. Dokumentacja jest przydatna, ale jest statyczna, a jej przeszukiwanie czÄ™sto wydaje siÄ™ nieporÄ™czne.

WÅ‚aÅ›nie tutaj pojawia siÄ™Â **RAG (Retrieval-Augmented Generation)**. Zamiast zmuszaÄ‡ uÅ¼ytkownikÃ³w do przeszukiwania tekstu, moÅ¼emy poÅ‚Ä…czyÄ‡Â **retrieval**Â (znalezienie odpowiednich fragmentÃ³w dokumentacji) zÂ **generation**Â (pozwolenie LLM na naturalne wyjaÅ›nienie).

W tym wpisie przeprowadzÄ™ CiÄ™ przez proces tworzenia chatbota dokumentacyjnego opartego na RAG i pokaÅ¼Ä™, jak nie tylko pomaga on uÅ¼ytkownikom szybciej znajdowaÄ‡ odpowiedzi, ale takÅ¼e daje zespoÅ‚om produktowym nowy sposÃ³b na zrozumienie problemÃ³w uÅ¼ytkownikÃ³w.

## Dlaczego warto uÅ¼ywaÄ‡ RAG do dokumentacji?

RAG staÅ‚ siÄ™ popularnym podejÅ›ciem nie bez powodu: jest to jeden z najbardziej praktycznych sposobÃ³w, aby duÅ¼e modele jÄ™zykowe staÅ‚y siÄ™ naprawdÄ™ uÅ¼yteczne.

Dla dokumentacji korzyÅ›ci sÄ… jasne:

- Natychmiastowe odpowiedzi: uÅ¼ytkownicy pytajÄ… w naturalnym jÄ™zyku i otrzymujÄ… odpowiednie odpowiedzi.
- Lepszy kontekst: model widzi tylko najbardziej istotne fragmenty dokumentacji, co redukuje halucynacje.
- Wyszukiwanie, ktÃ³re wydaje siÄ™ ludzkie: coÅ› na ksztaÅ‚t poÅ‚Ä…czenia Algolii + FAQ + chatbota w jednym.
- PÄ™tla informacji zwrotnej: przechowujÄ…c zapytania, odkrywasz, z czym uÅ¼ytkownicy naprawdÄ™ majÄ… problemy.

Ten ostatni punkt jest kluczowy. System RAG nie tylko odpowiada na pytania, ale takÅ¼e pokazuje, o co ludzie pytajÄ…. Oznacza to:

- Odkrywasz brakujÄ…ce informacje w swojej dokumentacji.
- Widujesz pojawiajÄ…ce siÄ™ proÅ›by o nowe funkcje.
- Dostrzegasz wzorce, ktÃ³re mogÄ… nawet kierowaÄ‡ strategiÄ… produktu.

Tak wiÄ™c RAG to nie tylko narzÄ™dzie wsparcia. To takÅ¼e **silnik odkrywania produktu**.

## Jak dziaÅ‚a pipeline RAG

![Pipeline RAG](https://github.com/aymericzip/intlayer/blob/main/docs/assets/rag_flow.svg)

Na wysokim poziomie, oto przepis, ktÃ³rego uÅ¼yÅ‚em:

1.  **Dzielenie dokumentacji na fragmenty** DuÅ¼e pliki Markdown sÄ… dzielone na fragmenty. Dzielenie pozwala dostarczyÄ‡ jako kontekst tylko odpowiednie czÄ™Å›ci dokumentacji.
2.  **Generowanie embeddingÃ³w** KaÅ¼dy fragment jest przeksztaÅ‚cany w wektor za pomocÄ… API embeddingÃ³w OpenAI (text-embedding-3-large) lub bazy danych wektorÃ³w (Chroma, Qdrant, Pinecone).
3.  **Indeksowanie i przechowywanie** Embeddingi sÄ… przechowywane w prostym pliku JSON (w moim demo), ale w produkcji prawdopodobnie uÅ¼yjesz bazy danych wektorÃ³w.
4.  **Wyszukiwanie (R w RAG)** Zapytanie uÅ¼ytkownika jest zamieniane na embedding, obliczana jest podobieÅ„stwo kosinusowe, a nastÄ™pnie pobierane sÄ… najlepiej dopasowane fragmenty.
5.  **Augmentacja + Generacja (AG w RAG)** Te fragmenty sÄ… wstrzykiwane do promptu dla ChatGPT, dziÄ™ki czemu model odpowiada z wykorzystaniem rzeczywistego kontekstu dokumentacji.
6.  **Logowanie zapytaÅ„ dla informacji zwrotnej** KaÅ¼de zapytanie uÅ¼ytkownika jest zapisywane. To zÅ‚oto dla zrozumienia problemÃ³w, brakujÄ…cych dokumentÃ³w lub nowych moÅ¼liwoÅ›ci.

## Krok 1: Odczytywanie dokumentacji

Pierwszy krok byÅ‚ prosty: potrzebowaÅ‚em sposobu na zeskanowanie folderu docs/ pod kÄ…tem wszystkich plikÃ³w .md. UÅ¼ywajÄ…c Node.js i glob, pobraÅ‚em zawartoÅ›Ä‡ kaÅ¼dego pliku Markdown do pamiÄ™ci.

To utrzymuje elastycznoÅ›Ä‡ pipelineâ€™u: zamiast Markdown, moÅ¼esz pobieraÄ‡ dokumentacjÄ™ z bazy danych, CMS-a lub nawet API.

## Krok 2: Dzielenie dokumentacji na fragmenty

Dlaczego dzieliÄ‡? PoniewaÅ¼ modele jÄ™zykowe majÄ… **ograniczenia kontekstu**. Podanie im caÅ‚ej ksiÄ…Å¼ki dokumentacji nie zadziaÅ‚a.

Dlatego pomysÅ‚ polega na podzieleniu tekstu na zarzÄ…dzalne fragmenty (np. po 500 tokenÃ³w kaÅ¼dy) z nakÅ‚adkÄ… (np. 100 tokenÃ³w). NakÅ‚adka zapewnia ciÄ…gÅ‚oÅ›Ä‡, dziÄ™ki czemu nie tracisz znaczenia na granicach fragmentÃ³w.

<p align="center">
  <img width="480" alt="Niezawodne ÅºrÃ³dÅ‚o danych" src="https://github.com/user-attachments/assets/ee548851-7206-4cc6-821e-de8a4366c6a3" />
</p>

**PrzykÅ‚ad:**

- Fragment 1 â†’ â€â€¦stara biblioteka, o ktÃ³rej wielu zapomniaÅ‚o. Jej wysokie pÃ³Å‚ki byÅ‚y wypeÅ‚nione ksiÄ…Å¼kamiâ€¦â€
- Fragment 2 â†’ â€â€¦pÃ³Å‚ki byÅ‚y wypeÅ‚nione ksiÄ…Å¼kami z kaÅ¼dego wyobraÅ¼alnego gatunku, z ktÃ³rych kaÅ¼dy szeptaÅ‚ historieâ€¦â€

NakÅ‚adanie siÄ™ fragmentÃ³w zapewnia, Å¼e oba zawierajÄ… wspÃ³lny kontekst, dziÄ™ki czemu wyszukiwanie pozostaje spÃ³jne.

Ten kompromis (rozmiar fragmentu vs nakÅ‚adanie) jest kluczowy dla efektywnoÅ›ci RAG:

- Zbyt maÅ‚y â†’ pojawia siÄ™ szum.
- Zbyt duÅ¼y â†’ rozrasta siÄ™ rozmiar kontekstu.

## Krok 3: Generowanie embeddingÃ³w

Gdy dokumenty sÄ… podzielone na fragmenty, generujemy **embeddingi** â€” wektory o wysokim wymiarze reprezentujÄ…ce kaÅ¼dy fragment.

UÅ¼yÅ‚em modelu OpenAI text-embedding-3-large, ale moÅ¼na uÅ¼yÄ‡ dowolnego nowoczesnego modelu embeddingowego.

**PrzykÅ‚adowy embedding:**

```js
[
  -0.0002630692, -0.029749284, 0.010225477, -0.009224428, -0.0065269712,
  -0.002665544, 0.003214777, 0.04235309, -0.033162255, -0.00080789323,
  //...+1533 elementÃ³w
];
```

KaÅ¼dy wektor jest matematycznym odciskiem tekstu, umoÅ¼liwiajÄ…cym wyszukiwanie podobieÅ„stw.

## Krok 4: Indeksowanie i przechowywanie embeddingÃ³w

Aby uniknÄ…Ä‡ wielokrotnego generowania embeddingÃ³w, zapisaÅ‚em je w plikuÂ embeddings.json.

W Å›rodowisku produkcyjnym prawdopodobnie bÄ™dziesz chciaÅ‚ uÅ¼yÄ‡ bazy danych wektorÃ³w, takiej jak:

- Chroma
- Qdrant
- Pinecone
- FAISS, Weaviate, Milvus itp.

Bazy danych wektorÃ³w zajmujÄ… siÄ™ indeksowaniem, skalowalnoÅ›ciÄ… i szybkim wyszukiwaniem. Jednak w moim prototypie lokalny plik JSON sprawdziÅ‚ siÄ™ dobrze.

## Krok 5: Wyszukiwanie z uÅ¼yciem podobieÅ„stwa kosinusowego

Gdy uÅ¼ytkownik zada pytanie:

1.  Wygeneruj embedding dla zapytania.
2.  PorÃ³wnaj go ze wszystkimi embeddingami dokumentÃ³w, uÅ¼ywajÄ…cÂ **podobieÅ„stwa kosinusowego**.
3.  Zachowaj tylko N najbardziej podobnych fragmentÃ³w.

PodobieÅ„stwo cosinusowe mierzy kÄ…t miÄ™dzy dwoma wektorami. Idealne dopasowanie uzyskuje wynikÂ **1.0**.

W ten sposÃ³b system znajduje najbliÅ¼sze fragmenty dokumentacji do zapytania.

## Krok 6: Rozszerzanie + Generowanie

Teraz zaczyna siÄ™ magia. Bierzemy najlepsze fragmenty i wstrzykujemy je doÂ **systemowego promptu**Â dla ChatGPT.

Oznacza to, Å¼e model odpowiada, jakby te fragmenty byÅ‚y czÄ™Å›ciÄ… rozmowy.

Efekt: dokÅ‚adne,Â **odpowiedzi oparte na dokumentacji**.

## Krok 7: Rejestrowanie zapytaÅ„ uÅ¼ytkownikÃ³w

To jest ukryta supermoc.

KaÅ¼de zadane pytanie jest zapisywane. Z czasem budujesz zbiÃ³r danych zawierajÄ…cy:

- NajczÄ™Å›ciej zadawane pytania (Å›wietne do FAQ)
- Niezadane pytania (brak dokumentacji lub niejasnoÅ›ci)
- ProÅ›by o funkcje ukryte w pytaniach (â€Czy integruje siÄ™ z X?â€)
- PojawiajÄ…ce siÄ™ przypadki uÅ¼ycia, ktÃ³rych nie planowaÅ‚eÅ›

To zamienia Twojego asystenta RAG wÂ **narzÄ™dzie do ciÄ…gÅ‚ych badaÅ„ uÅ¼ytkownikÃ³w**.

## Ile to kosztuje?

Jednym z czÄ™stych zarzutÃ³w wobec RAG jest koszt. W praktyce jest zaskakujÄ…co tani:

- Generowanie embeddingÃ³w dla okoÅ‚o 200 dokumentÃ³w zajmuje okoÅ‚oÂ **5 minut**Â i kosztujeÂ **1â€“2 euro**.
- Funkcja wyszukiwania w dokumentacji jest caÅ‚kowicie darmowa.
- Do zapytaÅ„ uÅ¼ywamyÂ gpt-4o-latestÂ bez trybu â€myÅ›leniaâ€. Na Intlayer obserwujemy okoÅ‚oÂ **300 zapytaÅ„ na czacie miesiÄ™cznie**, a rachunek za API OpenAI rzadko przekraczaÂ **10 dolarÃ³w**.

Do tego dochodzi koszt hostingu.

## SzczegÃ³Å‚y implementacji

Stack:

- Monorepo: pnpm workspace
- Pakiet dokumentacji: Node.js / TypeScript / OpenAI API
- Frontend: Next.js / React / Tailwind CSS
- Backend: Node.js API route / OpenAI API

Pakiet `@smart-doc/docs` to pakiet TypeScript, ktÃ³ry zajmuje siÄ™ przetwarzaniem dokumentacji. Gdy plik markdown zostanie dodany lub zmodyfikowany, pakiet zawiera skrypt `build`, ktÃ³ry przebudowuje listÄ™ dokumentacji w kaÅ¼dym jÄ™zyku, generuje embeddingi i zapisuje je w pliku `embeddings.json`.

Dla frontend-u uÅ¼ywamy aplikacji Next.js, ktÃ³ra oferuje:

- Renderowanie Markdown do HTML
- Pasek wyszukiwania do znajdowania odpowiedniej dokumentacji
- Interfejs chatbota do zadawania pytaÅ„ dotyczÄ…cych dokumentacji

Aby przeprowadziÄ‡ wyszukiwanie w dokumentacji, aplikacja Next.js zawiera trasÄ™ API, ktÃ³ra wywoÅ‚uje funkcjÄ™ z pakietu `@smart-doc/docs`, aby pobraÄ‡ fragmenty dokumentÃ³w pasujÄ…ce do zapytania. KorzystajÄ…c z tych fragmentÃ³w, moÅ¼emy zwrÃ³ciÄ‡ listÄ™ stron dokumentacji istotnych dla wyszukiwania uÅ¼ytkownika.

Dla funkcjonalnoÅ›ci chatbota stosujemy ten sam proces wyszukiwania, ale dodatkowo wstrzykujemy pobrane fragmenty dokumentacji do promptu wysyÅ‚anego do ChatGPT.

Oto przykÅ‚ad promptu wysyÅ‚anego do ChatGPT:

System prompt:

```txt
JesteÅ› pomocnym asystentem, ktÃ³ry potrafi odpowiadaÄ‡ na pytania dotyczÄ…ce dokumentacji Intlayer.

PowiÄ…zane fragmenty:

-----
docName: "getting-started"
docChunk: "1/3"
docUrl: "https://example.com/docs/en/getting-started"
---

# Jak zaczÄ…Ä‡

...

-----
docName: "another-doc"
docChunk: "1/5"
docUrl: "https://example.com/docs/en/another-doc"
---

# Inny dokument

...
```

Zapytanie uÅ¼ytkownika:

```txt
Jak zaczÄ…Ä‡?
```

UÅ¼ywamy SSE do strumieniowania odpowiedzi z trasy API.

Jak wspomniano, uÅ¼ywamy gpt-4-turbo bez trybu "myÅ›lenia". Odpowiedzi sÄ… trafne, a opÃ³Åºnienia niskie.
EksperymentowaliÅ›my z gpt-5, ale opÃ³Åºnienia byÅ‚y zbyt duÅ¼e (czasami do 15 sekund na odpowiedÅº). Jednak wrÃ³cimy do tego w przyszÅ‚oÅ›ci.

ğŸ‘‰Â [WyprÃ³buj demo tutaj](https://intlayer.org/doc/pl/why) ğŸ‘‰Â [SprawdÅº szablon kodu na GitHub](https://github.com/aymericzip/smart_doc_RAG)

## IdÄ…c dalej

Ten projekt to minimalna implementacja. MoÅ¼esz jÄ… jednak rozbudowaÄ‡ na wiele sposobÃ³w:

- Serwer MCP â†’ funkcja wyszukiwania w dokumentacji jako serwer MCP, aby poÅ‚Ä…czyÄ‡ dokumentacjÄ™ z dowolnym asystentem AI

- Bazy danych wektorowych â†’ skalowanie do milionÃ³w fragmentÃ³w dokumentÃ³w
- LangChain / LlamaIndex â†’ gotowe frameworki do pipelineâ€™Ã³w RAG
- Panele analityczne â†’ wizualizacja zapytaÅ„ uÅ¼ytkownikÃ³w i problemÃ³w
- WieloÅºrÃ³dÅ‚owe pobieranie â†’ pobieranie nie tylko dokumentÃ³w, ale teÅ¼ wpisÃ³w z baz danych, postÃ³w na blogach, zgÅ‚oszeÅ„ itp.
- Ulepszone promptowanie â†’ ponowne rankowanie, filtrowanie i wyszukiwanie hybrydowe (sÅ‚owo kluczowe + semantyczne)

## Ograniczenia, na ktÃ³re natrafiliÅ›my

- Dzielenie na fragmenty i nakÅ‚adanie siÄ™ jest empiryczne. Odpowiednia rÃ³wnowaga (rozmiar fragmentu, procent nakÅ‚adania, liczba pobieranych fragmentÃ³w) wymaga iteracji i testowania.
- Embeddingi nie sÄ… automatycznie regenerowane, gdy dokumentacja siÄ™ zmienia. Nasz system resetuje embeddingi dla pliku tylko wtedy, gdy liczba fragmentÃ³w rÃ³Å¼ni siÄ™ od zapisanej.
- W tym prototypie embeddingi sÄ… przechowywane w formacie JSON. DziaÅ‚a to w demo, ale zaÅ›mieca repozytorium Git. W produkcji lepsza jest baza danych lub dedykowany magazyn wektorÃ³w.

## Dlaczego to ma znaczenie poza dokumentacjÄ…

InteresujÄ…ca jest nie tylko sama chatbot. To jest **pÄ™tla informacji zwrotnej**.

DziÄ™ki RAG nie tylko odpowiadasz:

- Dowiadujesz siÄ™, co myli uÅ¼ytkownikÃ³w.
- Odkrywasz, jakich funkcji oczekujÄ….
- Dostosowujesz swojÄ… strategiÄ™ produktowÄ… na podstawie rzeczywistych zapytaÅ„.

**PrzykÅ‚ad:**

WyobraÅº sobie, Å¼e wprowadzasz nowÄ… funkcjÄ™ i natychmiast widzisz:

- 50% pytaÅ„ dotyczy tego samego niejasnego kroku konfiguracji
- UÅ¼ytkownicy wielokrotnie proszÄ… o integracjÄ™, ktÃ³rej jeszcze nie obsÅ‚ugujesz
- Ludzie wyszukujÄ… terminy, ktÃ³re ujawniajÄ… nowe zastosowanie

To jest **inteligencja produktowa** prosto od Twoich uÅ¼ytkownikÃ³w.

## Podsumowanie

RAG to jeden z najprostszych i najpotÄ™Å¼niejszych sposobÃ³w na praktyczne wykorzystanie LLM. ÅÄ…czÄ…c **wyszukiwanie + generowanie**, moÅ¼esz przeksztaÅ‚ciÄ‡ statycznÄ… dokumentacjÄ™ w **inteligentnego asystenta** i jednoczeÅ›nie uzyskaÄ‡ ciÄ…gÅ‚y strumieÅ„ informacji o produkcie.

Dla mnie ten projekt pokazaÅ‚, Å¼e RAG to nie tylko techniczny trik. To sposÃ³b na przeksztaÅ‚cenie dokumentacji w:

- interaktywny system wsparcia
- kanaÅ‚ informacji zwrotnej
- narzÄ™dzie do strategii produktowej

ğŸ‘‰ [WyprÃ³buj demo tutaj](https://intlayer.org/doc/why) ğŸ‘‰ [SprawdÅº szablon kodu na GitHub](https://github.com/aymericzip/smart_doc_RAG)

A jeÅ›li rÃ³wnieÅ¼ eksperymentujesz z RAG, chÄ™tnie usÅ‚yszÄ™, jak go uÅ¼ywasz.
